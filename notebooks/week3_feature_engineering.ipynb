{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adf83b5b-97a9-43fa-a48a-d23e44708632",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Workspace/Users/zinu.tommy%40gmail.com/.bundle/marvelous-databricks-course-tommydejong/dev/files\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Checking if build backend supports build_editable: started\n  Checking if build backend supports build_editable: finished with status 'done'\n  Getting requirements to build editable: started\n  Getting requirements to build editable: finished with status 'done'\n  Installing backend dependencies: started\n  Installing backend dependencies: finished with status 'done'\n  Preparing editable metadata (pyproject.toml): started\n  Preparing editable metadata (pyproject.toml): finished with status 'done'\nCollecting mlflow==2.17.0 (from fifa-players==0.0.1)\n  Obtaining dependency information for mlflow==2.17.0 from https://files.pythonhosted.org/packages/bd/af/fdf92ad9f654f2210f225a56b4d45698f6f171d69c1195461b9fa18c5543/mlflow-2.17.0-py3-none-any.whl.metadata\n  Using cached mlflow-2.17.0-py3-none-any.whl.metadata (29 kB)\nCollecting cffi==1.17.1 (from fifa-players==0.0.1)\n  Obtaining dependency information for cffi==1.17.1 from https://files.pythonhosted.org/packages/ff/6b/d45873c5e0242196f042d555526f92aa9e0c32355a1be1ff8c27f077fd37/cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Using cached cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting cloudpickle==3.1.0 (from fifa-players==0.0.1)\n  Obtaining dependency information for cloudpickle==3.1.0 from https://files.pythonhosted.org/packages/48/41/e1d85ca3cab0b674e277c8c4f678cf66a91cd2cecf93df94353a606fe0db/cloudpickle-3.1.0-py3-none-any.whl.metadata\n  Using cached cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\nCollecting matplotlib==3.9.2 (from fifa-players==0.0.1)\n  Obtaining dependency information for matplotlib==3.9.2 from https://files.pythonhosted.org/packages/01/75/6c7ce560e95714a10fcbb3367d1304975a1a3e620f72af28921b796403f3/matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Using cached matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting numpy==1.26.4 (from fifa-players==0.0.1)\n  Obtaining dependency information for numpy==1.26.4 from https://files.pythonhosted.org/packages/3a/d0/edc009c27b406c4f9cbc79274d6e46d634d139075492ad055e3d68445925/numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\nCollecting pandas==2.2.3 (from fifa-players==0.0.1)\n  Obtaining dependency information for pandas==2.2.3 from https://files.pythonhosted.org/packages/cd/5f/4dba1d39bb9c38d574a9a22548c540177f78ea47b32f99c0ff2ec499fac5/pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\nCollecting psutil==6.0.0 (from fifa-players==0.0.1)\n  Obtaining dependency information for psutil==6.0.0 from https://files.pythonhosted.org/packages/19/74/f59e7e0d392bc1070e9a70e2f9190d652487ac115bb16e2eff6b22ad1d24/psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Using cached psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nRequirement already satisfied: pyarrow==14.0.1 in /databricks/python3/lib/python3.11/site-packages (from fifa-players==0.0.1) (14.0.1)\nCollecting scikit-learn==1.5.2 (from fifa-players==0.0.1)\n  Obtaining dependency information for scikit-learn==1.5.2 from https://files.pythonhosted.org/packages/49/21/3723de321531c9745e40f1badafd821e029d346155b6c79704e0b7197552/scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Using cached scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nCollecting lightgbm==4.5.0 (from fifa-players==0.0.1)\n  Obtaining dependency information for lightgbm==4.5.0 from https://files.pythonhosted.org/packages/4e/19/1b928cad70a4e1a3e2c37d5417ca2182510f2451eaadb6c91cd9ec692cae/lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata\n  Using cached lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\nCollecting scipy==1.14.1 (from fifa-players==0.0.1)\n  Obtaining dependency information for scipy==1.14.1 from https://files.pythonhosted.org/packages/93/6b/701776d4bd6bdd9b629c387b5140f006185bd8ddea16788a44434376b98f/scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Using cached scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\nCollecting databricks-feature-engineering==0.6 (from fifa-players==0.0.1)\n  Obtaining dependency information for databricks-feature-engineering==0.6 from https://files.pythonhosted.org/packages/ae/73/ab301d1b538014c91fc4481b7e13c374cc60dd2cb0c0ea0ebf36a3f789c6/databricks_feature_engineering-0.6.0-py3-none-any.whl.metadata\n  Using cached databricks_feature_engineering-0.6.0-py3-none-any.whl.metadata (4.2 kB)\nCollecting databricks-feature-lookup==1.2.0 (from fifa-players==0.0.1)\n  Obtaining dependency information for databricks-feature-lookup==1.2.0 from https://files.pythonhosted.org/packages/20/16/d5464c1d6a11896d956dd9b9854c7072ca87333a8d788e3bd176b062bcf5/databricks_feature_lookup-1.2.0-py3-none-any.whl.metadata\n  Using cached databricks_feature_lookup-1.2.0-py3-none-any.whl.metadata (4.5 kB)\nCollecting databricks-sdk==0.32.0 (from fifa-players==0.0.1)\n  Obtaining dependency information for databricks-sdk==0.32.0 from https://files.pythonhosted.org/packages/b5/a7/0f7ce505b256c4b25bd9ce2ffc4304a77e78f933e942d80f11809e2b0a28/databricks_sdk-0.32.0-py3-none-any.whl.metadata\n  Using cached databricks_sdk-0.32.0-py3-none-any.whl.metadata (37 kB)\nCollecting pydantic==2.9.2 (from fifa-players==0.0.1)\n  Obtaining dependency information for pydantic==2.9.2 from https://files.pythonhosted.org/packages/df/e4/ba44652d562cbf0bf320e0f3810206149c8a4e99cdbf66da82e97ab53a15/pydantic-2.9.2-py3-none-any.whl.metadata\n  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\nCollecting loguru==0.7.3 (from fifa-players==0.0.1)\n  Obtaining dependency information for loguru==0.7.3 from https://files.pythonhosted.org/packages/0c/29/0348de65b8cc732daa3e33e67806420b2ae89bdce2b04af740289c5c6c8c/loguru-0.7.3-py3-none-any.whl.metadata\n  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\nCollecting python-dotenv>=1.1.0 (from fifa-players==0.0.1)\n  Obtaining dependency information for python-dotenv>=1.1.0 from https://files.pythonhosted.org/packages/1e/18/98a99ad95133c6a6e2005fe89faedf294a748bd5dc803008059409ac9b1e/python_dotenv-1.1.0-py3-none-any.whl.metadata\n  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.11/site-packages (from cffi==1.17.1->fifa-players==0.0.1) (2.21)\nRequirement already satisfied: mlflow-skinny[databricks]<3,>=2.11.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->fifa-players==0.0.1) (2.11.4)\nRequirement already satisfied: pyyaml<7,>=6 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->fifa-players==0.0.1) (6.0)\nRequirement already satisfied: boto3<2,>=1.16.7 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->fifa-players==0.0.1) (1.34.39)\nCollecting dbl-tempo<1,>=0.1.26 (from databricks-feature-engineering==0.6->fifa-players==0.0.1)\n  Obtaining dependency information for dbl-tempo<1,>=0.1.26 from https://files.pythonhosted.org/packages/1a/66/18cab25fbffe683e336add1279e7b7fc4b2d2509d56aaf782f36838df0b5/dbl_tempo-0.1.29-py3-none-any.whl.metadata\n  Using cached dbl_tempo-0.1.29-py3-none-any.whl.metadata (11 kB)\nCollecting azure-cosmos==4.3.1 (from databricks-feature-engineering==0.6->fifa-players==0.0.1)\n  Obtaining dependency information for azure-cosmos==4.3.1 from https://files.pythonhosted.org/packages/1a/e6/8fdeb60b1a5d2a9128a038056acaca64ee87a68cbe2f18dfe8a91cb4e5c2/azure_cosmos-4.3.1-py3-none-any.whl.metadata\n  Using cached azure_cosmos-4.3.1-py3-none-any.whl.metadata (52 kB)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->fifa-players==0.0.1) (4.24.1)\nCollecting flask<3,>=1.1.2 (from databricks-feature-engineering==0.6->fifa-players==0.0.1)\n  Obtaining dependency information for flask<3,>=1.1.2 from https://files.pythonhosted.org/packages/fd/56/26f0be8adc2b4257df20c1c4260ddd0aa396cf8e75d90ab2f7ff99bc34f9/flask-2.3.3-py3-none-any.whl.metadata\n  Using cached flask-2.3.3-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->fifa-players==0.0.1) (0.5.0)\nCollecting sqlalchemy>=1.4.8 (from databricks-feature-lookup==1.2.0->fifa-players==0.0.1)\n  Obtaining dependency information for sqlalchemy>=1.4.8 from https://files.pythonhosted.org/packages/62/e4/b9a7a0e5c6f79d49bcd6efb6e90d7536dc604dab64582a9dec220dab54b6/sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Using cached sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\nCollecting pymysql>=1.0.2 (from databricks-feature-lookup==1.2.0->fifa-players==0.0.1)\n  Obtaining dependency information for pymysql>=1.0.2 from https://files.pythonhosted.org/packages/0c/94/e4181a1f6286f545507528c78016e00065ea913276888db2262507693ce5/PyMySQL-1.1.1-py3-none-any.whl.metadata\n  Using cached PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: requests==2.* in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-lookup==1.2.0->fifa-players==0.0.1) (2.31.0)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk==0.32.0->fifa-players==0.0.1) (2.31.0)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (1.0.5)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (23.2)\nRequirement already satisfied: pillow>=8 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (9.4.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (2.8.2)\nCollecting mlflow-skinny==2.17.0 (from mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for mlflow-skinny==2.17.0 from https://files.pythonhosted.org/packages/a3/35/2821869a7c78e50148e460406834c4d8aa863d361b7084a8e923f18be474/mlflow_skinny-2.17.0-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.17.0-py3-none-any.whl.metadata (30 kB)\nCollecting alembic!=1.10.0,<2 (from mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for alembic!=1.10.0,<2 from https://files.pythonhosted.org/packages/31/59/565286efff3692c5716c212202af61466480f6357c4ae3089d4453bff1f3/alembic-1.16.1-py3-none-any.whl.metadata\n  Using cached alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\nCollecting docker<8,>=4.0.0 (from mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for docker<8,>=4.0.0 from https://files.pythonhosted.org/packages/e3/26/57c6fb270950d476074c087527a558ccb6f4436657314bfb6cdf484114c4/docker-7.1.0-py3-none-any.whl.metadata\n  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting graphene<4 (from mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for graphene<4 from https://files.pythonhosted.org/packages/66/e0/61d8e98007182e6b2aca7cf65904721fb2e4bce0192272ab9cb6f69d8812/graphene-3.4.3-py2.py3-none-any.whl.metadata\n  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting markdown<4,>=3.3 (from mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for markdown<4,>=3.3 from https://files.pythonhosted.org/packages/51/3f/afe76f8e2246ffbc867440cbcf90525264df0e658f8a5ca1f872b3f6192a/markdown-3.8-py3-none-any.whl.metadata\n  Using cached markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\nCollecting Jinja2<4,>=2.11 (from mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for Jinja2<4,>=2.11 from https://files.pythonhosted.org/packages/62/a1/3d680cbfd5f4b8f15abc1d571870c5fc3e594bb582bc3b64ea099db13e56/jinja2-3.1.6-py3-none-any.whl.metadata\n  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\nCollecting gunicorn<24 (from mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for gunicorn<24 from https://files.pythonhosted.org/packages/cb/7d/6dac2a6e1eba33ee43f318edbed4ff29151a49b5d37f080aad1e6469bca4/gunicorn-23.0.0-py3-none-any.whl.metadata\n  Using cached gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas==2.2.3->fifa-players==0.0.1) (2022.7)\nCollecting tzdata>=2022.7 (from pandas==2.2.3->fifa-players==0.0.1)\n  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl.metadata\n  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting annotated-types>=0.6.0 (from pydantic==2.9.2->fifa-players==0.0.1)\n  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\nCollecting pydantic-core==2.23.4 (from pydantic==2.9.2->fifa-players==0.0.1)\n  Obtaining dependency information for pydantic-core==2.23.4 from https://files.pythonhosted.org/packages/44/31/a3899b5ce02c4316865e390107f145089876dff7e1dfc770a231d836aed8/pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Using cached pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: typing-extensions>=4.6.1 in /databricks/python3/lib/python3.11/site-packages (from pydantic==2.9.2->fifa-players==0.0.1) (4.10.0)\nRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn==1.5.2->fifa-players==0.0.1) (1.2.0)\nCollecting threadpoolctl>=3.1.0 (from scikit-learn==1.5.2->fifa-players==0.0.1)\n  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl.metadata\n  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: azure-core<2.0.0,>=1.23.0 in /databricks/python3/lib/python3.11/site-packages (from azure-cosmos==4.3.1->databricks-feature-engineering==0.6->fifa-players==0.0.1) (1.30.2)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (5.3.3)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (8.0.4)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (3.1.43)\nRequirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (6.0.0)\nCollecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for opentelemetry-api<3,>=1.9.0 from https://files.pythonhosted.org/packages/05/44/4c45a34def3506122ae61ad684139f0bbc4e00c39555d4f7e20e0e001c8a/opentelemetry_api-1.33.1-py3-none-any.whl.metadata\n  Using cached opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\nCollecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for opentelemetry-sdk<3,>=1.9.0 from https://files.pythonhosted.org/packages/df/8e/ae2d0742041e0bd7fe0d2dcc5e7cce51dcf7d3961a26072d5b43cc8fa2a7/opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata\n  Using cached opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup==1.2.0->fifa-players==0.0.1) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup==1.2.0->fifa-players==0.0.1) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup==1.2.0->fifa-players==0.0.1) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup==1.2.0->fifa-players==0.0.1) (2023.7.22)\nCollecting Mako (from alembic!=1.10.0,<2->mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for Mako from https://files.pythonhosted.org/packages/87/fb/99f81ac72ae23375f22b7afdb7642aba97c00a713c217124420147681a2f/mako-1.3.10-py3-none-any.whl.metadata\n  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\nCollecting typing-extensions>=4.6.1 (from pydantic==2.9.2->fifa-players==0.0.1)\n  Obtaining dependency information for typing-extensions>=4.6.1 from https://files.pythonhosted.org/packages/8b/54/b1ae86c0973cc6f0210b53d508ca3641fb6d0c56823f288d108bc7ab3cc8/typing_extensions-4.13.2-py3-none-any.whl.metadata\n  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: botocore<1.35.0,>=1.34.39 in /databricks/python3/lib/python3.11/site-packages (from boto3<2,>=1.16.7->databricks-feature-engineering==0.6->fifa-players==0.0.1) (1.34.39)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.11/site-packages (from boto3<2,>=1.16.7->databricks-feature-engineering==0.6->fifa-players==0.0.1) (0.10.0)\nRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /databricks/python3/lib/python3.11/site-packages (from boto3<2,>=1.16.7->databricks-feature-engineering==0.6->fifa-players==0.0.1) (0.10.2)\nCollecting Werkzeug>=2.3.7 (from flask<3,>=1.1.2->databricks-feature-engineering==0.6->fifa-players==0.0.1)\n  Obtaining dependency information for Werkzeug>=2.3.7 from https://files.pythonhosted.org/packages/52/24/ab44c871b0f07f491e5d2ad12c9bd7358e527510618cb1b803a88e986db1/werkzeug-3.1.3-py3-none-any.whl.metadata\n  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\nCollecting itsdangerous>=2.1.2 (from flask<3,>=1.1.2->databricks-feature-engineering==0.6->fifa-players==0.0.1)\n  Obtaining dependency information for itsdangerous>=2.1.2 from https://files.pythonhosted.org/packages/04/96/92447566d16df59b2a776c0fb82dbc4d9e07cd95062562af01e408583fc4/itsdangerous-2.2.0-py3-none-any.whl.metadata\n  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\nCollecting click<9,>=7.0 (from mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for click<9,>=7.0 from https://files.pythonhosted.org/packages/85/32/10bb5764d90a8eee674e9dc6f4db6a0ab47c8c4d0d83c27f7c39ac415a4d/click-8.2.1-py3-none-any.whl.metadata\n  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting blinker>=1.6.2 (from flask<3,>=1.1.2->databricks-feature-engineering==0.6->fifa-players==0.0.1)\n  Obtaining dependency information for blinker>=1.6.2 from https://files.pythonhosted.org/packages/10/cb/f2ad4230dc2eb1a74edf38f1a38b9b52277f75bef262d8908e60d957e13c/blinker-1.9.0-py3-none-any.whl.metadata\n  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk==0.32.0->fifa-players==0.0.1) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk==0.32.0->fifa-players==0.0.1) (4.9)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for graphql-core<3.3,>=3.1 from https://files.pythonhosted.org/packages/ae/4f/7297663840621022bc73c22d7d9d80dbc78b4db6297f764b545cd5dd462d/graphql_core-3.2.6-py3-none-any.whl.metadata\n  Using cached graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for graphql-relay<3.3,>=3.1 from https://files.pythonhosted.org/packages/74/16/a4cf06adbc711bd364a73ce043b0b08d8fa5aae3df11b6ee4248bcdad2e0/graphql_relay-3.2.0-py3-none-any.whl.metadata\n  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nCollecting MarkupSafe>=2.0 (from Jinja2<4,>=2.11->mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/f1/a4/aefb044a2cd8d7334c8a47d3fb2c9f328ac48cb349468cc31c20b539305f/MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nINFO: pip is looking at multiple versions of mlflow-skinny[databricks] to determine which version is compatible with other requirements. This could take a while.\nCollecting mlflow-skinny[databricks]<3,>=2.11.0 (from databricks-feature-engineering==0.6->fifa-players==0.0.1)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/f4/eb/53dd2a5db1040a21da2980c382ebe3a9bda2d8af8365c2d01053c924b150/mlflow_skinny-2.22.0-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.22.0-py3-none-any.whl.metadata (31 kB)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/2d/f8/b71f88ca373f248fd7fdf3751f74c7b36a71b7ee2b5f4b803ee053ac963a/mlflow_skinny-2.21.3-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.21.3-py3-none-any.whl.metadata (31 kB)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/e2/ec/adfbccfac31e0d85003d74e03694a30ba54b5e0e3c7783de64952e9c3b84/mlflow_skinny-2.21.2-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.21.2-py3-none-any.whl.metadata (31 kB)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/f4/5b/866da8a061105a382eafef79da6926314b3e324b9f6a6db244a1c0376253/mlflow_skinny-2.21.1-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.21.1-py3-none-any.whl.metadata (31 kB)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/a3/a9/4295421f222308da8b78c749756a835e292dcda94a01f4710c7ca457adf2/mlflow_skinny-2.21.0-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.21.0-py3-none-any.whl.metadata (31 kB)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/85/56/342f8c4393c84404ed7234d80f9dc274141aab465befa921ae957dac8c8d/mlflow_skinny-2.20.4-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.20.4-py3-none-any.whl.metadata (31 kB)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/39/f6/c55a49753098ae8469bb5c1b177298b65ac68f4a7334dd37b727cdcd72eb/mlflow_skinny-2.20.3-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.20.3-py3-none-any.whl.metadata (31 kB)\nINFO: pip is still looking at multiple versions of mlflow-skinny[databricks] to determine which version is compatible with other requirements. This could take a while.\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/7b/95/2c1f8a1f02fc581e0fd46725facae2ff647e947323867e579f1f8178c01c/mlflow_skinny-2.20.2-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.20.2-py3-none-any.whl.metadata (31 kB)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/b4/43/4e633b6141930c8dffb72ef597e9ad687b5cf5b443d6c924520850129721/mlflow_skinny-2.20.1-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.20.1-py3-none-any.whl.metadata (31 kB)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/28/e7/c00b1a7a594200f3bce448a18a0f26da9cd4939cbf08b19f93135d2204ab/mlflow_skinny-2.20.0-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.20.0-py3-none-any.whl.metadata (31 kB)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/05/95/75f59715e39aa2224e5ecd8c52d5a305467e16a843ade2235a215599a1fa/mlflow_skinny-2.19.0-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.19.0-py3-none-any.whl.metadata (31 kB)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/2e/1b/20128a015405fdfda2dce38b975acf19cd532f4c8dc4231fd088fb8553dd/mlflow_skinny-2.18.0-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.18.0-py3-none-any.whl.metadata (30 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/51/66/47784192b65ba3b5a48b2a1b2d0f42d211db0bfb799183b64fdcdd5d24e1/mlflow_skinny-2.17.2-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.17.2-py3-none-any.whl.metadata (30 kB)\n  Obtaining dependency information for mlflow-skinny[databricks]<3,>=2.11.0 from https://files.pythonhosted.org/packages/73/7b/9a2088bf3b294c9195920a2dbbc3d4bcb6b6cbe0085e6ea5fb98ba529791/mlflow_skinny-2.17.1-py3-none-any.whl.metadata\n  Using cached mlflow_skinny-2.17.1-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: azure-storage-file-datalake>12 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (12.14.0)\nRequirement already satisfied: google-cloud-storage>=1.30.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (2.17.0)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.9.2->fifa-players==0.0.1) (1.16.0)\nCollecting greenlet>=1 (from sqlalchemy>=1.4.8->databricks-feature-lookup==1.2.0->fifa-players==0.0.1)\n  Obtaining dependency information for greenlet>=1 from https://files.pythonhosted.org/packages/4b/29/b130946b57e3ceb039238413790dd3793c5e7b8e14a54968de1fe449a7cf/greenlet-3.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata\n  Using cached greenlet-3.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: azure-storage-blob<13.0.0,>=12.19.0 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (12.19.1)\nRequirement already satisfied: isodate>=0.6.1 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (0.6.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (4.0.11)\nRequirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (2.18.0)\nRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (2.4.1)\nRequirement already satisfied: google-resumable-media>=2.6.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (2.7.1)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (1.5.0)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (3.11.0)\nCollecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for deprecated>=1.2.6 from https://files.pythonhosted.org/packages/6e/c6/ac0b6c1e2d138f1002bcf799d330bd6d85084fece321e662a14223794041/Deprecated-1.2.18-py2.py3-none-any.whl.metadata\n  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\nCollecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for opentelemetry-semantic-conventions==0.54b1 from https://files.pythonhosted.org/packages/0a/80/08b1698c52ff76d96ba440bf15edc2f4bc0a279868778928e947c1004bdd/opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata\n  Using cached opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk==0.32.0->fifa-players==0.0.1) (0.4.8)\nRequirement already satisfied: cryptography>=2.1.4 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (41.0.3)\nCollecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1)\n  Obtaining dependency information for wrapt<2,>=1.10 from https://files.pythonhosted.org/packages/b4/b0/9fc566b0fe08b282c850063591a756057c3247b2362b9286429ec5bf1721/wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (5.0.1)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /databricks/python3/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=1.30.0->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (1.63.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /databricks/python3/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=1.30.0->mlflow-skinny==2.17.0->mlflow==2.17.0->fifa-players==0.0.1) (1.24.0)\nUsing cached cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (467 kB)\nUsing cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)\nUsing cached databricks_feature_engineering-0.6.0-py3-none-any.whl (253 kB)\nUsing cached databricks_feature_lookup-1.2.0-py3-none-any.whl (98 kB)\nUsing cached databricks_sdk-0.32.0-py3-none-any.whl (551 kB)\nUsing cached lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\nUsing cached loguru-0.7.3-py3-none-any.whl (61 kB)\nUsing cached matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\nUsing cached mlflow-2.17.0-py3-none-any.whl (26.7 MB)\nUsing cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\nUsing cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\nUsing cached psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\nUsing cached pydantic-2.9.2-py3-none-any.whl (434 kB)\nUsing cached scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\nUsing cached scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\nUsing cached azure_cosmos-4.3.1-py3-none-any.whl (222 kB)\nUsing cached mlflow_skinny-2.17.0-py3-none-any.whl (5.7 MB)\nUsing cached pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\nUsing cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nUsing cached alembic-1.16.1-py3-none-any.whl (242 kB)\nUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\nUsing cached dbl_tempo-0.1.29-py3-none-any.whl (41 kB)\nUsing cached docker-7.1.0-py3-none-any.whl (147 kB)\nUsing cached flask-2.3.3-py3-none-any.whl (96 kB)\nUsing cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\nUsing cached gunicorn-23.0.0-py3-none-any.whl (85 kB)\nUsing cached jinja2-3.1.6-py3-none-any.whl (134 kB)\nUsing cached markdown-3.8-py3-none-any.whl (106 kB)\nUsing cached PyMySQL-1.1.1-py3-none-any.whl (44 kB)\nUsing cached sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\nUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\nUsing cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\nUsing cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\nUsing cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\nUsing cached click-8.2.1-py3-none-any.whl (102 kB)\nUsing cached graphql_core-3.2.6-py3-none-any.whl (203 kB)\nUsing cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nUsing cached greenlet-3.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (583 kB)\nUsing cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\nUsing cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nUsing cached opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\nUsing cached opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\nUsing cached opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\nUsing cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\nUsing cached mako-1.3.10-py3-none-any.whl (78 kB)\nUsing cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\nUsing cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\nBuilding wheels for collected packages: fifa-players\n  Building editable for fifa-players (pyproject.toml): started\n  Building editable for fifa-players (pyproject.toml): finished with status 'done'\n  Created wheel for fifa-players: filename=fifa_players-0.0.1-0.editable-py3-none-any.whl size=1773 sha256=1e40ae426ef5f5a40b9bfdeba8318a3c9fc73a1ee0f5e2c6ceeae7bd68865f08\n  Stored in directory: /tmp/pip-ephem-wheel-cache-9i6_jogy/wheels/26/73/49/a97ed40bc3e732af2deabc4d481e606a1ebf4106fbb6ec4c15\nSuccessfully built fifa-players\nInstalling collected packages: dbl-tempo, wrapt, tzdata, typing-extensions, threadpoolctl, python-dotenv, pymysql, psutil, numpy, MarkupSafe, markdown, loguru, itsdangerous, gunicorn, greenlet, graphql-core, cloudpickle, click, cffi, blinker, annotated-types, Werkzeug, sqlalchemy, scipy, pydantic-core, pandas, Mako, Jinja2, graphql-relay, docker, deprecated, scikit-learn, pydantic, opentelemetry-api, matplotlib, lightgbm, graphene, flask, databricks-sdk, azure-cosmos, alembic, opentelemetry-semantic-conventions, opentelemetry-sdk, mlflow-skinny, mlflow, databricks-feature-lookup, databricks-feature-engineering, fifa-players\n  Attempting uninstall: tzdata\n    Found existing installation: tzdata 2022.1\n    Not uninstalling tzdata at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'tzdata'. No files were found to uninstall.\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.10.0\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: threadpoolctl\n    Found existing installation: threadpoolctl 2.2.0\n    Not uninstalling threadpoolctl at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'threadpoolctl'. No files were found to uninstall.\n  Attempting uninstall: psutil\n    Found existing installation: psutil 5.9.0\n    Not uninstalling psutil at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'psutil'. No files were found to uninstall.\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Not uninstalling numpy at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'numpy'. No files were found to uninstall.\n  Attempting uninstall: cloudpickle\n    Found existing installation: cloudpickle 2.2.1\n    Not uninstalling cloudpickle at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'cloudpickle'. No files were found to uninstall.\n  Attempting uninstall: click\n    Found existing installation: click 8.0.4\n    Not uninstalling click at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'click'. No files were found to uninstall.\n  Attempting uninstall: cffi\n    Found existing installation: cffi 1.15.1\n    Not uninstalling cffi at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'cffi'. No files were found to uninstall.\n  Attempting uninstall: blinker\n    Found existing installation: blinker 1.4\n    Not uninstalling blinker at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'blinker'. No files were found to uninstall.\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.11.1\n    Not uninstalling scipy at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'scipy'. No files were found to uninstall.\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.5.3\n    Not uninstalling pandas at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'pandas'. No files were found to uninstall.\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.3.0\n    Not uninstalling scikit-learn at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'scikit-learn'. No files were found to uninstall.\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.10.6\n    Not uninstalling pydantic at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'pydantic'. No files were found to uninstall.\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.2\n    Not uninstalling matplotlib at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'matplotlib'. No files were found to uninstall.\n  Attempting uninstall: databricks-sdk\n    Found existing installation: databricks-sdk 0.20.0\n    Not uninstalling databricks-sdk at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'databricks-sdk'. No files were found to uninstall.\n  Attempting uninstall: mlflow-skinny\n    Found existing installation: mlflow-skinny 2.11.4\n    Not uninstalling mlflow-skinny at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'mlflow-skinny'. No files were found to uninstall.\nSuccessfully installed Jinja2-3.1.6 Mako-1.3.10 MarkupSafe-3.0.2 Werkzeug-3.1.3 alembic-1.16.1 annotated-types-0.7.0 azure-cosmos-4.3.1 blinker-1.9.0 cffi-1.17.1 click-8.2.1 cloudpickle-3.1.0 databricks-feature-engineering-0.6.0 databricks-feature-lookup-1.2.0 databricks-sdk-0.32.0 dbl-tempo-0.1.29 deprecated-1.2.18 docker-7.1.0 fifa-players-0.0.1 flask-2.3.3 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 greenlet-3.2.2 gunicorn-23.0.0 itsdangerous-2.2.0 lightgbm-4.5.0 loguru-0.7.3 markdown-3.8 matplotlib-3.9.2 mlflow-2.17.0 mlflow-skinny-2.17.0 numpy-1.26.4 opentelemetry-api-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 pandas-2.2.3 psutil-6.0.0 pydantic-2.9.2 pydantic-core-2.23.4 pymysql-1.1.1 python-dotenv-1.1.0 scikit-learn-1.5.2 scipy-1.14.1 sqlalchemy-2.0.41 threadpoolctl-3.6.0 typing-extensions-4.13.2 tzdata-2025.2 wrapt-1.17.2\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting git+https://github.com/end-to-end-mlops-databricks-3/marvelous@0.1.0\n  Cloning https://github.com/end-to-end-mlops-databricks-3/marvelous (to revision 0.1.0) to /tmp/pip-req-build-afqnv3xo\n  Running command git clone --filter=blob:none --quiet https://github.com/end-to-end-mlops-databricks-3/marvelous /tmp/pip-req-build-afqnv3xo\n  Resolved https://github.com/end-to-end-mlops-databricks-3/marvelous to commit 7fc6264a3f6c1401662fa2ce0d31972b50d0d0fb\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Installing backend dependencies: started\n  Installing backend dependencies: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nCollecting requests>=2.32.3 (from marvelous==0.1.0)\n  Obtaining dependency information for requests>=2.32.3 from https://files.pythonhosted.org/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl.metadata\n  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: loguru==0.7.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from marvelous==0.1.0) (0.7.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.32.3->marvelous==0.1.0) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.32.3->marvelous==0.1.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.32.3->marvelous==0.1.0) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.32.3->marvelous==0.1.0) (2023.7.22)\nUsing cached requests-2.32.3-py3-none-any.whl (64 kB)\nBuilding wheels for collected packages: marvelous\n  Building wheel for marvelous (pyproject.toml): started\n  Building wheel for marvelous (pyproject.toml): finished with status 'done'\n  Created wheel for marvelous: filename=marvelous-0.1.0-py3-none-any.whl size=5788 sha256=b02ec129bb8c8d27c61cd06d70e39c75d830226ea5f36476c7ff687a97722d67\n  Stored in directory: /tmp/pip-ephem-wheel-cache-qt8awi1e/wheels/5d/57/73/b648ba8e04db42ae5b40d91c83e810124ec16d8961a9859aa4\nSuccessfully built marvelous\nInstalling collected packages: requests, marvelous\n  Attempting uninstall: requests\n    Found existing installation: requests 2.31.0\n    Not uninstalling requests at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f\n    Can't uninstall 'requests'. No files were found to uninstall.\nSuccessfully installed marvelous-0.1.0 requests-2.32.3\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "%pip install -e ..\n",
    "%pip install git+https://github.com/end-to-end-mlops-databricks-3/marvelous@0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a5bf02b-3ce6-4953-abd4-ca619469b651",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#restart python\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ae18bd4-185d-476b-b870-639b53de700f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# system path update, must be after %restart_python\n",
    "# caution! This is not a great approach\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4599ef9-65ab-46eb-a14f-e6e69e444306",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Workspace/Users/zinu.tommy@gmail.com/.bundle/marvelous-databricks-course-tommydejong/dev/files/dist/fifa_players-0.0.1-py3-none-any.whl\nRequirement already satisfied: mlflow==2.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (2.17.0)\nRequirement already satisfied: cffi==1.17.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (1.17.1)\nRequirement already satisfied: cloudpickle==3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (3.1.0)\nRequirement already satisfied: matplotlib==3.9.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (3.9.2)\nRequirement already satisfied: numpy==1.26.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (1.26.4)\nRequirement already satisfied: pandas==2.2.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (2.2.3)\nRequirement already satisfied: psutil==6.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (6.0.0)\nRequirement already satisfied: pyarrow==14.0.1 in /databricks/python3/lib/python3.11/site-packages (from fifa-players==0.0.1) (14.0.1)\nRequirement already satisfied: scikit-learn==1.5.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (1.5.2)\nRequirement already satisfied: lightgbm==4.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (4.5.0)\nRequirement already satisfied: scipy==1.14.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (1.14.1)\nRequirement already satisfied: databricks-feature-engineering==0.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (0.6.0)\nRequirement already satisfied: databricks-feature-lookup==1.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (1.2.0)\nRequirement already satisfied: databricks-sdk==0.32.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (0.32.0)\nRequirement already satisfied: pydantic==2.9.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (2.9.2)\nRequirement already satisfied: loguru==0.7.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (0.7.3)\nRequirement already satisfied: python-dotenv>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from fifa-players==0.0.1) (1.1.0)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.11/site-packages (from cffi==1.17.1->fifa-players==0.0.1) (2.21)\nRequirement already satisfied: mlflow-skinny[databricks]<3,>=2.11.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->fifa-players==0.0.1) (2.17.0)\nRequirement already satisfied: pyyaml<7,>=6 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->fifa-players==0.0.1) (6.0)\nRequirement already satisfied: boto3<2,>=1.16.7 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->fifa-players==0.0.1) (1.34.39)\nRequirement already satisfied: dbl-tempo<1,>=0.1.26 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->fifa-players==0.0.1) (0.1.29)\nRequirement already satisfied: azure-cosmos==4.3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->fifa-players==0.0.1) (4.3.1)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->fifa-players==0.0.1) (4.24.1)\nRequirement already satisfied: flask<3,>=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->fifa-players==0.0.1) (2.3.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-feature-engineering==0.6->fifa-players==0.0.1) (0.5.0)\nRequirement already satisfied: sqlalchemy>=1.4.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from databricks-feature-lookup==1.2.0->fifa-players==0.0.1) (2.0.41)\nRequirement already satisfied: pymysql>=1.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from databricks-feature-lookup==1.2.0->fifa-players==0.0.1) (1.1.1)\nRequirement already satisfied: requests==2.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from databricks-feature-lookup==1.2.0->fifa-players==0.0.1) (2.32.3)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk==0.32.0->fifa-players==0.0.1) (2.31.0)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (1.0.5)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (23.2)\nRequirement already satisfied: pillow>=8 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (9.4.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.11/site-packages (from matplotlib==3.9.2->fifa-players==0.0.1) (2.8.2)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from mlflow==2.17.0->fifa-players==0.0.1) (1.16.1)\nRequirement already satisfied: docker<8,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from mlflow==2.17.0->fifa-players==0.0.1) (7.1.0)\nRequirement already satisfied: graphene<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from mlflow==2.17.0->fifa-players==0.0.1) (3.4.3)\nRequirement already satisfied: markdown<4,>=3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from mlflow==2.17.0->fifa-players==0.0.1) (3.8)\nRequirement already satisfied: Jinja2<4,>=2.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from mlflow==2.17.0->fifa-players==0.0.1) (3.1.6)\nRequirement already satisfied: gunicorn<24 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from mlflow==2.17.0->fifa-players==0.0.1) (23.0.0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas==2.2.3->fifa-players==0.0.1) (2022.7)\nRequirement already satisfied: tzdata>=2022.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from pandas==2.2.3->fifa-players==0.0.1) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from pydantic==2.9.2->fifa-players==0.0.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from pydantic==2.9.2->fifa-players==0.0.1) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from pydantic==2.9.2->fifa-players==0.0.1) (4.13.2)\nRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn==1.5.2->fifa-players==0.0.1) (1.2.0)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from scikit-learn==1.5.2->fifa-players==0.0.1) (3.6.0)\nRequirement already satisfied: azure-core<2.0.0,>=1.23.0 in /databricks/python3/lib/python3.11/site-packages (from azure-cosmos==4.3.1->databricks-feature-engineering==0.6->fifa-players==0.0.1) (1.30.2)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (5.3.3)\nRequirement already satisfied: click<9,>=7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (8.2.1)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (3.1.43)\nRequirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (6.0.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (1.33.1)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (1.33.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup==1.2.0->fifa-players==0.0.1) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup==1.2.0->fifa-players==0.0.1) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup==1.2.0->fifa-players==0.0.1) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests==2.*->databricks-feature-lookup==1.2.0->fifa-players==0.0.1) (2023.7.22)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow==2.17.0->fifa-players==0.0.1) (1.3.10)\nRequirement already satisfied: botocore<1.35.0,>=1.34.39 in /databricks/python3/lib/python3.11/site-packages (from boto3<2,>=1.16.7->databricks-feature-engineering==0.6->fifa-players==0.0.1) (1.34.39)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.11/site-packages (from boto3<2,>=1.16.7->databricks-feature-engineering==0.6->fifa-players==0.0.1) (0.10.0)\nRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /databricks/python3/lib/python3.11/site-packages (from boto3<2,>=1.16.7->databricks-feature-engineering==0.6->fifa-players==0.0.1) (0.10.2)\nRequirement already satisfied: Werkzeug>=2.3.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from flask<3,>=1.1.2->databricks-feature-engineering==0.6->fifa-players==0.0.1) (3.1.3)\nRequirement already satisfied: itsdangerous>=2.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from flask<3,>=1.1.2->databricks-feature-engineering==0.6->fifa-players==0.0.1) (2.2.0)\nRequirement already satisfied: blinker>=1.6.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from flask<3,>=1.1.2->databricks-feature-engineering==0.6->fifa-players==0.0.1) (1.9.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk==0.32.0->fifa-players==0.0.1) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk==0.32.0->fifa-players==0.0.1) (4.9)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from graphene<4->mlflow==2.17.0->fifa-players==0.0.1) (3.2.6)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from graphene<4->mlflow==2.17.0->fifa-players==0.0.1) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow==2.17.0->fifa-players==0.0.1) (3.0.2)\nRequirement already satisfied: azure-storage-file-datalake>12 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (12.14.0)\nRequirement already satisfied: google-cloud-storage>=1.30.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (2.17.0)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.9.2->fifa-players==0.0.1) (1.16.0)\nRequirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from sqlalchemy>=1.4.8->databricks-feature-lookup==1.2.0->fifa-players==0.0.1) (3.2.2)\nRequirement already satisfied: azure-storage-blob<13.0.0,>=12.19.0 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (12.19.1)\nRequirement already satisfied: isodate>=0.6.1 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (0.6.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (4.0.11)\nRequirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (2.18.0)\nRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (2.4.1)\nRequirement already satisfied: google-resumable-media>=2.6.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (2.7.1)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (1.5.0)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (3.11.0)\nRequirement already satisfied: deprecated>=1.2.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (1.2.18)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.54b1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (0.54b1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk==0.32.0->fifa-players==0.0.1) (0.4.8)\nRequirement already satisfied: cryptography>=2.1.4 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (41.0.3)\nRequirement already satisfied: wrapt<2,>=1.10 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (1.17.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (5.0.1)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /databricks/python3/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=1.30.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (1.63.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /databricks/python3/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=1.30.0->mlflow-skinny[databricks]<3,>=2.11.0->databricks-feature-engineering==0.6->fifa-players==0.0.1) (1.24.0)\nInstalling collected packages: fifa-players\n  Attempting uninstall: fifa-players\n    Found existing installation: fifa-players 0.0.1\n    Uninstalling fifa-players-0.0.1:\n      Successfully uninstalled fifa-players-0.0.1\nSuccessfully installed fifa-players-0.0.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# A better approach (this file must be present in a notebook folder, achieved via synchronization)\n",
    "%pip install ../dist/fifa_players-0.0.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "671ddb7e-3b22-4783-88fa-ad29897cace0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import mlflow\n",
    "\n",
    "from fifa_players import __version__\n",
    "from fifa_players.config import ProjectConfig\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from mlflow.models import infer_signature\n",
    "from marvelous.common import is_databricks\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from mlflow import MlflowClient\n",
    "import pandas as pd\n",
    "from mlflow.utils.environment import _mlflow_conda_env\n",
    "from databricks import feature_engineering\n",
    "from databricks.feature_engineering import FeatureFunction, FeatureLookup\n",
    "from pyspark.errors import AnalysisException\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d668dc8-29a6-46cc-8fdf-b62b0eb2763d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not is_databricks():\n",
    "    load_dotenv()\n",
    "    profile = os.environ[\"PROFILE\"]\n",
    "    mlflow.set_tracking_uri(f\"databricks://{profile}\")\n",
    "    mlflow.set_registry_uri(f\"databricks-uc://{profile}\")\n",
    "\n",
    "\n",
    "config = ProjectConfig.from_yaml(config_path=\"../project_config.yml\", env=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de0563d3-135b-4eed-a0be-f3ff4d3bb9de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "fe = feature_engineering.FeatureEngineeringClient()\n",
    "\n",
    "train_set = spark.table(f\"{config.catalog_name}.{config.schema_name}.train_set\")\n",
    "test_set = spark.table(f\"{config.catalog_name}.{config.schema_name}.test_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58ed12b0-37f3-4320-9b69-ad5d8d068635",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create feature table with information about players\n",
    "\n",
    "feature_table_name = f\"{config.catalog_name}.{config.schema_name}.player_features\"\n",
    "lookup_features = [\"overall_rating\", \"potential\", \"release_clause_euro\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0881256a-9ee6-4106-9e64-31e2d5f6fb41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-129403519654909>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Option 1: feature engineering client\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m feature_table \u001B[38;5;241m=\u001B[39m fe\u001B[38;5;241m.\u001B[39mcreate_table(\n",
       "\u001B[1;32m      3\u001B[0m    name\u001B[38;5;241m=\u001B[39mfeature_table_name,\n",
       "\u001B[1;32m      4\u001B[0m    primary_keys\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mId\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n",
       "\u001B[1;32m      5\u001B[0m    df\u001B[38;5;241m=\u001B[39mtrain_set[lookup_features],\n",
       "\u001B[1;32m      6\u001B[0m    description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlayer features table\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      7\u001B[0m )\n",
       "\u001B[1;32m      9\u001B[0m spark\u001B[38;5;241m.\u001B[39msql(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mALTER TABLE \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfeature_table_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m     11\u001B[0m fe\u001B[38;5;241m.\u001B[39mwrite_table(\n",
       "\u001B[1;32m     12\u001B[0m    name\u001B[38;5;241m=\u001B[39mfeature_table_name,\n",
       "\u001B[1;32m     13\u001B[0m    df\u001B[38;5;241m=\u001B[39mtest_set[lookup_features],\n",
       "\u001B[1;32m     14\u001B[0m    mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmerge\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     15\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages/databricks/feature_engineering/client.py:338\u001B[0m, in \u001B[0;36mFeatureEngineeringClient.create_table\u001B[0;34m(self, name, primary_keys, df, timeseries_column, partition_columns, schema, description, tags, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    327\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    328\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTimeseries column \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtimeseries_column\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not in primary_keys. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    329\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTimeseries columns must be primary keys.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    330\u001B[0m     )\n",
       "\u001B[1;32m    332\u001B[0m name \u001B[38;5;241m=\u001B[39m uc_utils\u001B[38;5;241m.\u001B[39mget_full_table_name(\n",
       "\u001B[1;32m    333\u001B[0m     name,\n",
       "\u001B[1;32m    334\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_spark_client\u001B[38;5;241m.\u001B[39mget_current_catalog(),\n",
       "\u001B[1;32m    335\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_spark_client\u001B[38;5;241m.\u001B[39mget_current_database(),\n",
       "\u001B[1;32m    336\u001B[0m )\n",
       "\u001B[0;32m--> 338\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_client\u001B[38;5;241m.\u001B[39mcreate_table(\n",
       "\u001B[1;32m    339\u001B[0m     name\u001B[38;5;241m=\u001B[39mname,\n",
       "\u001B[1;32m    340\u001B[0m     primary_keys\u001B[38;5;241m=\u001B[39mprimary_keys,\n",
       "\u001B[1;32m    341\u001B[0m     df\u001B[38;5;241m=\u001B[39mdf,\n",
       "\u001B[1;32m    342\u001B[0m     timestamp_keys\u001B[38;5;241m=\u001B[39mas_list(timeseries_column, default\u001B[38;5;241m=\u001B[39m[]),\n",
       "\u001B[1;32m    343\u001B[0m     partition_columns\u001B[38;5;241m=\u001B[39mpartition_columns,\n",
       "\u001B[1;32m    344\u001B[0m     schema\u001B[38;5;241m=\u001B[39mschema,\n",
       "\u001B[1;32m    345\u001B[0m     description\u001B[38;5;241m=\u001B[39mdescription,\n",
       "\u001B[1;32m    346\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n",
       "\u001B[1;32m    347\u001B[0m     client_name\u001B[38;5;241m=\u001B[39mrequest_context\u001B[38;5;241m.\u001B[39mFEATURE_ENGINEERING_CLIENT,\n",
       "\u001B[1;32m    348\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n",
       "\u001B[1;32m    349\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages/databricks/ml_features/_compute_client/_compute_client.py:108\u001B[0m, in \u001B[0;36mComputeClient.create_table\u001B[0;34m(self, name, primary_keys, df, timestamp_keys, partition_columns, schema, description, tags, client_name, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    105\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPath argument is not supported for Unity Catalog tables.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    106\u001B[0m validation_utils\u001B[38;5;241m.\u001B[39mcheck_kwargs_empty(kwargs, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcreate_table\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[0;32m--> 108\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_table(\n",
       "\u001B[1;32m    109\u001B[0m     name,\n",
       "\u001B[1;32m    110\u001B[0m     primary_keys,\n",
       "\u001B[1;32m    111\u001B[0m     df,\n",
       "\u001B[1;32m    112\u001B[0m     timestamp_keys\u001B[38;5;241m=\u001B[39mtimestamp_keys,\n",
       "\u001B[1;32m    113\u001B[0m     partition_columns\u001B[38;5;241m=\u001B[39mpartition_columns,\n",
       "\u001B[1;32m    114\u001B[0m     schema\u001B[38;5;241m=\u001B[39mschema,\n",
       "\u001B[1;32m    115\u001B[0m     description\u001B[38;5;241m=\u001B[39mdescription,\n",
       "\u001B[1;32m    116\u001B[0m     path\u001B[38;5;241m=\u001B[39mpath,\n",
       "\u001B[1;32m    117\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n",
       "\u001B[1;32m    118\u001B[0m     req_context\u001B[38;5;241m=\u001B[39mRequestContext(\n",
       "\u001B[1;32m    119\u001B[0m         request_context\u001B[38;5;241m.\u001B[39mCREATE_TABLE, client_name\u001B[38;5;241m=\u001B[39mclient_name\n",
       "\u001B[1;32m    120\u001B[0m     ),\n",
       "\u001B[1;32m    121\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages/databricks/ml_features/_compute_client/_compute_client.py:175\u001B[0m, in \u001B[0;36mComputeClient._create_table\u001B[0;34m(self, name, primary_keys, df, timestamp_keys, partition_columns, schema, description, path, tags, req_context)\u001B[0m\n",
       "\u001B[1;32m    170\u001B[0m     ComputeClient\u001B[38;5;241m.\u001B[39m_check_schema_has_columns(\n",
       "\u001B[1;32m    171\u001B[0m         table_schema, partition_cols_as_list, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpartition columns\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    172\u001B[0m     )\n",
       "\u001B[1;32m    174\u001B[0m primary_keys_as_list \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mas_list(primary_keys)\n",
       "\u001B[0;32m--> 175\u001B[0m ComputeClient\u001B[38;5;241m.\u001B[39m_check_schema_has_columns(\n",
       "\u001B[1;32m    176\u001B[0m     table_schema, primary_keys_as_list, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprimary keys\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    177\u001B[0m )\n",
       "\u001B[1;32m    179\u001B[0m timestamp_keys_as_list \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mas_list(timestamp_keys, default\u001B[38;5;241m=\u001B[39m[])\n",
       "\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timestamp_keys:\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages/databricks/ml_features/_compute_client/_compute_client.py:972\u001B[0m, in \u001B[0;36mComputeClient._check_schema_has_columns\u001B[0;34m(schema, columns, col_type)\u001B[0m\n",
       "\u001B[1;32m    970\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m columns:\n",
       "\u001B[1;32m    971\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m col \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m schema_cols:\n",
       "\u001B[0;32m--> 972\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    973\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe provided DataFrame or schema must contain all specified \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcol_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    974\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSchema \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mschema\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is missing column \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcol\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    975\u001B[0m         )\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: The provided DataFrame or schema must contain all specified primary keys. Schema StructType([StructField('overall_rating', LongType(), True), StructField('potential', LongType(), True), StructField('release_clause_euro', DoubleType(), True)]) is missing column 'Id'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "The provided DataFrame or schema must contain all specified primary keys. Schema StructType([StructField('overall_rating', LongType(), True), StructField('potential', LongType(), True), StructField('release_clause_euro', DoubleType(), True)]) is missing column 'Id'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ValueError</span>: The provided DataFrame or schema must contain all specified primary keys. Schema StructType([StructField('overall_rating', LongType(), True), StructField('potential', LongType(), True), StructField('release_clause_euro', DoubleType(), True)]) is missing column 'Id'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-129403519654909>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Option 1: feature engineering client\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m feature_table \u001B[38;5;241m=\u001B[39m fe\u001B[38;5;241m.\u001B[39mcreate_table(\n\u001B[1;32m      3\u001B[0m    name\u001B[38;5;241m=\u001B[39mfeature_table_name,\n\u001B[1;32m      4\u001B[0m    primary_keys\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mId\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m      5\u001B[0m    df\u001B[38;5;241m=\u001B[39mtrain_set[lookup_features],\n\u001B[1;32m      6\u001B[0m    description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlayer features table\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      7\u001B[0m )\n\u001B[1;32m      9\u001B[0m spark\u001B[38;5;241m.\u001B[39msql(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mALTER TABLE \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfeature_table_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     11\u001B[0m fe\u001B[38;5;241m.\u001B[39mwrite_table(\n\u001B[1;32m     12\u001B[0m    name\u001B[38;5;241m=\u001B[39mfeature_table_name,\n\u001B[1;32m     13\u001B[0m    df\u001B[38;5;241m=\u001B[39mtest_set[lookup_features],\n\u001B[1;32m     14\u001B[0m    mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmerge\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     15\u001B[0m )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages/databricks/feature_engineering/client.py:338\u001B[0m, in \u001B[0;36mFeatureEngineeringClient.create_table\u001B[0;34m(self, name, primary_keys, df, timeseries_column, partition_columns, schema, description, tags, **kwargs)\u001B[0m\n\u001B[1;32m    327\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTimeseries column \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtimeseries_column\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not in primary_keys. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    329\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTimeseries columns must be primary keys.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    330\u001B[0m     )\n\u001B[1;32m    332\u001B[0m name \u001B[38;5;241m=\u001B[39m uc_utils\u001B[38;5;241m.\u001B[39mget_full_table_name(\n\u001B[1;32m    333\u001B[0m     name,\n\u001B[1;32m    334\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_spark_client\u001B[38;5;241m.\u001B[39mget_current_catalog(),\n\u001B[1;32m    335\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_spark_client\u001B[38;5;241m.\u001B[39mget_current_database(),\n\u001B[1;32m    336\u001B[0m )\n\u001B[0;32m--> 338\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_client\u001B[38;5;241m.\u001B[39mcreate_table(\n\u001B[1;32m    339\u001B[0m     name\u001B[38;5;241m=\u001B[39mname,\n\u001B[1;32m    340\u001B[0m     primary_keys\u001B[38;5;241m=\u001B[39mprimary_keys,\n\u001B[1;32m    341\u001B[0m     df\u001B[38;5;241m=\u001B[39mdf,\n\u001B[1;32m    342\u001B[0m     timestamp_keys\u001B[38;5;241m=\u001B[39mas_list(timeseries_column, default\u001B[38;5;241m=\u001B[39m[]),\n\u001B[1;32m    343\u001B[0m     partition_columns\u001B[38;5;241m=\u001B[39mpartition_columns,\n\u001B[1;32m    344\u001B[0m     schema\u001B[38;5;241m=\u001B[39mschema,\n\u001B[1;32m    345\u001B[0m     description\u001B[38;5;241m=\u001B[39mdescription,\n\u001B[1;32m    346\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    347\u001B[0m     client_name\u001B[38;5;241m=\u001B[39mrequest_context\u001B[38;5;241m.\u001B[39mFEATURE_ENGINEERING_CLIENT,\n\u001B[1;32m    348\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    349\u001B[0m )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages/databricks/ml_features/_compute_client/_compute_client.py:108\u001B[0m, in \u001B[0;36mComputeClient.create_table\u001B[0;34m(self, name, primary_keys, df, timestamp_keys, partition_columns, schema, description, tags, client_name, **kwargs)\u001B[0m\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPath argument is not supported for Unity Catalog tables.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    106\u001B[0m validation_utils\u001B[38;5;241m.\u001B[39mcheck_kwargs_empty(kwargs, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcreate_table\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 108\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_table(\n\u001B[1;32m    109\u001B[0m     name,\n\u001B[1;32m    110\u001B[0m     primary_keys,\n\u001B[1;32m    111\u001B[0m     df,\n\u001B[1;32m    112\u001B[0m     timestamp_keys\u001B[38;5;241m=\u001B[39mtimestamp_keys,\n\u001B[1;32m    113\u001B[0m     partition_columns\u001B[38;5;241m=\u001B[39mpartition_columns,\n\u001B[1;32m    114\u001B[0m     schema\u001B[38;5;241m=\u001B[39mschema,\n\u001B[1;32m    115\u001B[0m     description\u001B[38;5;241m=\u001B[39mdescription,\n\u001B[1;32m    116\u001B[0m     path\u001B[38;5;241m=\u001B[39mpath,\n\u001B[1;32m    117\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    118\u001B[0m     req_context\u001B[38;5;241m=\u001B[39mRequestContext(\n\u001B[1;32m    119\u001B[0m         request_context\u001B[38;5;241m.\u001B[39mCREATE_TABLE, client_name\u001B[38;5;241m=\u001B[39mclient_name\n\u001B[1;32m    120\u001B[0m     ),\n\u001B[1;32m    121\u001B[0m )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages/databricks/ml_features/_compute_client/_compute_client.py:175\u001B[0m, in \u001B[0;36mComputeClient._create_table\u001B[0;34m(self, name, primary_keys, df, timestamp_keys, partition_columns, schema, description, path, tags, req_context)\u001B[0m\n\u001B[1;32m    170\u001B[0m     ComputeClient\u001B[38;5;241m.\u001B[39m_check_schema_has_columns(\n\u001B[1;32m    171\u001B[0m         table_schema, partition_cols_as_list, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpartition columns\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    172\u001B[0m     )\n\u001B[1;32m    174\u001B[0m primary_keys_as_list \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mas_list(primary_keys)\n\u001B[0;32m--> 175\u001B[0m ComputeClient\u001B[38;5;241m.\u001B[39m_check_schema_has_columns(\n\u001B[1;32m    176\u001B[0m     table_schema, primary_keys_as_list, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprimary keys\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    177\u001B[0m )\n\u001B[1;32m    179\u001B[0m timestamp_keys_as_list \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mas_list(timestamp_keys, default\u001B[38;5;241m=\u001B[39m[])\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timestamp_keys:\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-34a8cc90-4a83-464d-af4b-42775841273f/lib/python3.11/site-packages/databricks/ml_features/_compute_client/_compute_client.py:972\u001B[0m, in \u001B[0;36mComputeClient._check_schema_has_columns\u001B[0;34m(schema, columns, col_type)\u001B[0m\n\u001B[1;32m    970\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m columns:\n\u001B[1;32m    971\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m col \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m schema_cols:\n\u001B[0;32m--> 972\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    973\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe provided DataFrame or schema must contain all specified \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcol_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    974\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSchema \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mschema\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is missing column \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcol\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    975\u001B[0m         )\n",
        "\u001B[0;31mValueError\u001B[0m: The provided DataFrame or schema must contain all specified primary keys. Schema StructType([StructField('overall_rating', LongType(), True), StructField('potential', LongType(), True), StructField('release_clause_euro', DoubleType(), True)]) is missing column 'Id'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Option 1: feature engineering client\n",
    "feature_table = fe.create_table(\n",
    "   name=feature_table_name,\n",
    "   primary_keys=[\"Id\"],\n",
    "   df=train_set[lookup_features],\n",
    "   description=\"Player features table\",\n",
    ")\n",
    "\n",
    "spark.sql(f\"ALTER TABLE {feature_table_name} SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")\n",
    "\n",
    "fe.write_table(\n",
    "   name=feature_table_name,\n",
    "   df=test_set[lookup_features],\n",
    "   mode=\"merge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf034afa-747d-49ff-9968-d36c5af20088",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create feature table with information about houses\n",
    "# Option 2: SQL\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "          CREATE OR REPLACE TABLE {feature_table_name}\n",
    "          (Id STRING NOT NULL, overall_rating INT, potential INT, release_clause_euro INT);\n",
    "          \"\"\")\n",
    "# primary key on Databricks is not enforced!\n",
    "try:\n",
    "    spark.sql(f\"ALTER TABLE {feature_table_name} ADD CONSTRAINT house_pk_demo PRIMARY KEY(Id);\")\n",
    "except AnalysisException:\n",
    "    pass\n",
    "spark.sql(f\"ALTER TABLE {feature_table_name} SET TBLPROPERTIES (delta.enableChangeDataFeed = true);\")\n",
    "spark.sql(f\"\"\"\n",
    "          INSERT INTO {feature_table_name}\n",
    "          SELECT Id, overall_rating, potential, release_clause_euro\n",
    "          FROM {config.catalog_name}.{config.schema_name}.train_set\n",
    "          \"\"\")\n",
    "spark.sql(f\"\"\"\n",
    "          INSERT INTO {feature_table_name}\n",
    "          SELECT Id, overall_rating, potential, release_clause_euro\n",
    "          FROM {config.catalog_name}.{config.schema_name}.test_set\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f5b6164-97f8-4478-a415-270881c042d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create feature function\n",
    "# docs: https://docs.databricks.com/aws/en/sql/language-manual/sql-ref-syntax-ddl-create-sql-function\n",
    "\n",
    "# problems with feature functions:\n",
    "# functions are not versioned \n",
    "# functions may behave differently depending on the runtime (and version of packages and python)\n",
    "# there is no way to enforce python version & package versions for the function \n",
    "# this is only supported from runtime 17\n",
    "# advised to use only for simple calculations\n",
    "\n",
    "function_name = f\"{config.catalog_name}.{config.schema_name}.calculate_potential_ratio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "827ff230-c29a-404a-82f8-1d77864b0ee9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Option 1: with Python\n",
    "spark.sql(f\"\"\"\n",
    "        CREATE OR REPLACE FUNCTION {function_name} (ratio FLOAT)\n",
    "        RETURNS INT\n",
    "        LANGUAGE PYTHON AS\n",
    "        $$\n",
    "        return datetime.now().year - year_built\n",
    "        $$\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08c7bbfc-b2b7-42df-a046-63a7a184919a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# it is possible to define simple functions in sql only without python\n",
    "# Option 2\n",
    "spark.sql(f\"\"\"\n",
    "        CREATE OR REPLACE FUNCTION {function_name}_sql (year_built BIGINT)\n",
    "        RETURNS INT\n",
    "        RETURN year(current_date()) - year_built;\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9decc0c-23f8-4350-bcb6-eab73ece85cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# execute function\n",
    "spark.sql(f\"SELECT {function_name}_sql(1960) as potential_ratio;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f2bc62c-2aa7-4e5c-9206-a3e5b46a0004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create a training set\n",
    "training_set = fe.create_training_set(\n",
    "    df=train_set.drop(\"OverallQual\", \"GrLivArea\", \"GarageCars\"),\n",
    "    label=config.target,\n",
    "    feature_lookups=[\n",
    "        FeatureLookup(\n",
    "            table_name=feature_table_name,\n",
    "            feature_names=[\"OverallQual\", \"GrLivArea\", \"GarageCars\"],\n",
    "            lookup_key=\"Id\",\n",
    "                ),\n",
    "        FeatureFunction(\n",
    "            udf_name=function_name,\n",
    "            output_name=\"house_age\",\n",
    "            input_bindings={\"year_built\": \"YearBuilt\"},\n",
    "            ),\n",
    "    ],\n",
    "    exclude_columns=[\"update_timestamp_utc\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5fef43c-4c73-42d1-b5ea-08c6a4c272eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train & register a model\n",
    "training_df = training_set.load_df().toPandas()\n",
    "X_train = training_df[config.num_features + config.cat_features + [\"house_age\"]]\n",
    "y_train = training_df[config.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dac9c79-d244-43d2-959c-ae1d50f91d45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "        steps=[(\"preprocessor\", ColumnTransformer(\n",
    "            transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "                           config.cat_features)],\n",
    "            remainder=\"passthrough\")\n",
    "            ),\n",
    "               (\"regressor\", LGBMRegressor(**config.parameters))]\n",
    "        )\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1059af09-5905-414b-a344-dd9b4c69a2a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"/Shared/demo-model-fe\")\n",
    "with mlflow.start_run(run_name=\"demo-run-model-fe\",\n",
    "                      tags={\"git_sha\": \"1234567890abcd\",\n",
    "                            \"branch\": \"week2\"},\n",
    "                            description=\"demo run for FE model logging\") as run:\n",
    "    # Log parameters and metrics\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM with preprocessing\")\n",
    "    mlflow.log_params(config.parameters)\n",
    "\n",
    "    # Log the model\n",
    "    signature = infer_signature(model_input=X_train, model_output=pipeline.predict(X_train))\n",
    "    fe.log_model(\n",
    "                model=pipeline,\n",
    "                flavor=mlflow.sklearn,\n",
    "                artifact_path=\"lightgbm-pipeline-model-fe\",\n",
    "                training_set=training_set,\n",
    "                signature=signature,\n",
    "            )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bd55aae-1980-423d-9a9f-497e336a62ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = f\"{config.catalog_name}.{config.schema_name}.model_fe_demo\"\n",
    "model_version = mlflow.register_model(\n",
    "    model_uri=f'runs:/{run_id}/lightgbm-pipeline-model-fe',\n",
    "    name=model_name,\n",
    "    tags={\"git_sha\": \"1234567890abcd\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8faace55-8af2-4e60-9914-33499fd808f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "features = [f for f in [\"Id\"] + config.num_features + config.cat_features if f not in lookup_features]\n",
    "predictions = fe.score_batch(\n",
    "    model_uri=f\"models:/{model_name}/{model_version.version}\",\n",
    "    df=test_set[features]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a5b3321-5ba6-42b0-a320-515b05376b8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions.select(\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f62def06-d15f-4394-a65f-298631215c32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "features = [f for f in [\"Id\"] + config.num_features + config.cat_features if f not in lookup_features]\n",
    "test_set_with_new_id = test_set.select(*features).withColumn(\n",
    "    \"Id\",\n",
    "    (col(\"Id\").cast(\"long\") + 1000000).cast(\"string\")\n",
    ")\n",
    "\n",
    "predictions = fe.score_batch(\n",
    "    model_uri=f\"models:/{model_name}/{model_version.version}\",\n",
    "    df=test_set_with_new_id \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69dc30da-a199-41d7-9d23-e2a1aa15135d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# make predictions for a non-existing entry -> error!\n",
    "predictions.select(\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "caf2aaf2-6191-4404-8254-e3d0d0c3694f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "overallqual_function = f\"{config.catalog_name}.{config.schema_name}.replace_overallqual_missing\"\n",
    "spark.sql(f\"\"\"\n",
    "        CREATE OR REPLACE FUNCTION {overallqual_function}(OverallQual INT)\n",
    "        RETURNS INT\n",
    "        LANGUAGE PYTHON AS\n",
    "        $$\n",
    "        if OverallQual is None:\n",
    "            return 5\n",
    "        else:\n",
    "            return OverallQual\n",
    "        $$\n",
    "        \"\"\")\n",
    "\n",
    "grlivarea_function = f\"{config.catalog_name}.{config.schema_name}.replace_grlivarea_missing\"\n",
    "spark.sql(f\"\"\"\n",
    "        CREATE OR REPLACE FUNCTION {grlivarea_function}(GrLivArea INT)\n",
    "        RETURNS INT\n",
    "        LANGUAGE PYTHON AS\n",
    "        $$\n",
    "        if GrLivArea is None:\n",
    "            return 1000\n",
    "        else:\n",
    "            return GrLivArea\n",
    "        $$\n",
    "        \"\"\")\n",
    "\n",
    "garagecars_function = f\"{config.catalog_name}.{config.schema_name}.replace_garagecars_missing\"\n",
    "spark.sql(f\"\"\"\n",
    "        CREATE OR REPLACE FUNCTION {garagecars_function}(GarageCars INT)\n",
    "        RETURNS INT\n",
    "        LANGUAGE PYTHON AS\n",
    "        $$\n",
    "        if GarageCars is None:\n",
    "            return 2\n",
    "        else:\n",
    "            return GarageCars\n",
    "        $$\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c41b562-9406-4269-87db-98f1a7927b7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# what if we want to replace with a default value if entry is not found\n",
    "# what if we want to look up value in another table? the logics get complex\n",
    "# problems that arize: functions/ lookups always get executed (if statememt is not possible)\n",
    "# it can get slow...\n",
    "\n",
    "# step 1: create 3 feature functions\n",
    "\n",
    "# step 2: redefine create training set\n",
    "\n",
    "# try again\n",
    "\n",
    "# create a training set\n",
    "training_set = fe.create_training_set(\n",
    "    df=train_set.drop(\"OverallQual\", \"GrLivArea\", \"GarageCars\"),\n",
    "    label=config.target,\n",
    "    feature_lookups=[\n",
    "        FeatureLookup(\n",
    "            table_name=feature_table_name,\n",
    "            feature_names=[\"OverallQual\", \"GrLivArea\", \"GarageCars\"],\n",
    "            lookup_key=\"Id\",\n",
    "            rename_outputs={\"OverallQual\": \"lookup_OverallQual\",\n",
    "                            \"GrLivArea\": \"lookup_GrLivArea\",\n",
    "                            \"GarageCars\": \"lookup_GarageCars\"}\n",
    "                ),\n",
    "        FeatureFunction(\n",
    "            udf_name=overallqual_function,\n",
    "            output_name=\"OverallQual\",\n",
    "            input_bindings={\"OverallQual\": \"lookup_OverallQual\"},\n",
    "            ),\n",
    "        FeatureFunction(\n",
    "            udf_name=grlivarea_function,\n",
    "            output_name=\"GrLivArea\",\n",
    "            input_bindings={\"GrLivArea\": \"lookup_GrLivArea\"},\n",
    "        ),\n",
    "        FeatureFunction(\n",
    "            udf_name=garagecars_function,\n",
    "            output_name=\"GarageCars\",\n",
    "            input_bindings={\"GarageCars\": \"lookup_GarageCars\"},\n",
    "        ),\n",
    "        FeatureFunction(\n",
    "            udf_name=function_name,\n",
    "            output_name=\"house_age\",\n",
    "            input_bindings={\"year_built\": \"YearBuilt\"},\n",
    "            ),\n",
    "    ],\n",
    "    exclude_columns=[\"update_timestamp_utc\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9b42dfb-9ecb-4ada-8434-e02afe1bfef6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train & register a model\n",
    "training_df = training_set.load_df().toPandas()\n",
    "X_train = training_df[config.num_features + config.cat_features + [\"house_age\"]]\n",
    "y_train = training_df[config.target]\n",
    "\n",
    "#pipeline\n",
    "pipeline = Pipeline(\n",
    "        steps=[(\"preprocessor\", ColumnTransformer(\n",
    "            transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "                           config.cat_features)],\n",
    "            remainder=\"passthrough\")\n",
    "            ),\n",
    "               (\"regressor\", LGBMRegressor(**config.parameters))]\n",
    "        )\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67ec76dd-cd32-4725-8e17-bdd348bb2067",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"/Shared/demo-model-fe\")\n",
    "with mlflow.start_run(run_name=\"demo-run-model-fe\",\n",
    "                      tags={\"git_sha\": \"1234567890abcd\",\n",
    "                            \"branch\": \"week2\"},\n",
    "                            description=\"demo run for FE model logging\") as run:\n",
    "    # Log parameters and metrics\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM with preprocessing\")\n",
    "    mlflow.log_params(config.parameters)\n",
    "\n",
    "    # Log the model\n",
    "    signature = infer_signature(model_input=X_train, model_output=pipeline.predict(X_train))\n",
    "    fe.log_model(\n",
    "                model=pipeline,\n",
    "                flavor=mlflow.sklearn,\n",
    "                artifact_path=\"lightgbm-pipeline-model-fe\",\n",
    "                training_set=training_set,\n",
    "                signature=signature,\n",
    "            )\n",
    "model_name = f\"{config.catalog_name}.{config.schema_name}.model_fe_demo\"\n",
    "model_version = mlflow.register_model(\n",
    "    model_uri=f'runs:/{run_id}/lightgbm-pipeline-model-fe',\n",
    "    name=model_name,\n",
    "    tags={\"git_sha\": \"1234567890abcd\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbe685bf-01de-44ac-be8f-0c1c1c848d8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "features = [f for f in [\"Id\"] + config.num_features + config.cat_features if f not in lookup_features]\n",
    "test_set_with_new_id = test_set.select(*features).withColumn(\n",
    "    \"Id\",\n",
    "    (col(\"Id\").cast(\"long\") + 1000000).cast(\"string\")\n",
    ")\n",
    "\n",
    "predictions = fe.score_batch(\n",
    "    model_uri=f\"models:/{model_name}/{model_version.version}\",\n",
    "    df=test_set_with_new_id \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "164deeaa-8e72-40f4-9fed-4bc975a87741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# make predictions for a non-existing entry -> no error!\n",
    "predictions.select(\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20b2d1c6-e9e0-4c25-b225-ab061e4f3a83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "region_name = \"eu-west-1\"\n",
    "aws_access_key_id = os.environ[\"aws_access_key_id\"]\n",
    "aws_secret_access_key = os.environ[\"aws_secret_access_key\"]\n",
    "\n",
    "client = boto3.client(\n",
    "    'dynamodb',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=region_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b968c3d3-8a2c-44dd-b8cf-650a757c5150",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response = client.create_table(\n",
    "    TableName='HouseFeatures',\n",
    "    KeySchema=[\n",
    "        {\n",
    "            'AttributeName': 'Id',\n",
    "            'KeyType': 'HASH'  # Partition key\n",
    "        }\n",
    "    ],\n",
    "    AttributeDefinitions=[\n",
    "        {\n",
    "            'AttributeName': 'Id',\n",
    "            'AttributeType': 'S'  # String\n",
    "        }\n",
    "    ],\n",
    "    ProvisionedThroughput={\n",
    "        'ReadCapacityUnits': 5,\n",
    "        'WriteCapacityUnits': 5\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Table creation initiated:\", response['TableDescription']['TableName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d22a757-7326-4e9d-9bc4-97774848c0d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client.put_item(\n",
    "    TableName='HouseFeatures',\n",
    "    Item={\n",
    "        'Id': {'S': 'house_001'},\n",
    "        'OverallQual': {'N': '8'},\n",
    "        'GrLivArea': {'N': '2450'},\n",
    "        'GarageCars': {'N': '2'}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca735ab9-47f2-431f-a9fc-566aaea89cdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response = client.get_item(\n",
    "    TableName='HouseFeatures',\n",
    "    Key={\n",
    "        'Id': {'S': 'house_001'}\n",
    "    }\n",
    ")\n",
    "\n",
    "# Extract the item from the response\n",
    "item = response.get('Item')\n",
    "print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39aa0b0c-8d30-4315-a54f-bea36393986d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "rows = spark.table(feature_table_name).toPandas().to_dict(orient=\"records\")\n",
    "\n",
    "def to_dynamodb_item(row):\n",
    "    return {\n",
    "        'PutRequest': {\n",
    "            'Item': {\n",
    "                'Id': {'S': str(row['Id'])},\n",
    "                'OverallQual': {'N': str(row['OverallQual'])},\n",
    "                'GrLivArea': {'N': str(row['GrLivArea'])},\n",
    "                'GarageCars': {'N': str(row['GarageCars'])}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "items = [to_dynamodb_item(row) for row in rows]\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "for batch in chunks(items, 25):\n",
    "    response = client.batch_write_item(\n",
    "        RequestItems={\n",
    "            'HouseFeatures': batch\n",
    "        }\n",
    "    )\n",
    "    # Handle any unprocessed items if needed\n",
    "    unprocessed = response.get('UnprocessedItems', {})\n",
    "    if unprocessed:\n",
    "        print(\"Warning: Some items were not processed. Retry logic needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4f76123-5309-4707-ad18-c7d4f8149ea4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We ran into more limitations when we tried complex data types as output of a feature function\n",
    "# and then tried to use it for serving\n",
    "# al alternatve solution: using an external database (we use DynamoDB here)\n",
    "\n",
    "# create a DynamoDB table\n",
    "# insert records into dynamo DB & read from dynamoDB\n",
    "\n",
    "# create a pyfunc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9431c249-edd1-498c-af4c-502b0c6cef99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class HousePriceModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"Wrapper class for machine learning models to be used with MLflow.\n",
    "\n",
    "    This class wraps a machine learning model for predicting house prices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: object) -> None:\n",
    "        \"\"\"Initialize the HousePriceModelWrapper.\n",
    "\n",
    "        :param model: The underlying machine learning model.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "\n",
    "    def predict(\n",
    "        self, context: mlflow.pyfunc.PythonModelContext, model_input: pd.DataFrame | np.ndarray\n",
    "    ) -> dict[str, float]:\n",
    "        \"\"\"Make predictions using the wrapped model.\n",
    "\n",
    "        :param context: The MLflow context (unused in this implementation).\n",
    "        :param model_input: Input data for making predictions.\n",
    "        :return: A dictionary containing the adjusted prediction.\n",
    "        \"\"\"\n",
    "        client = boto3.client('dynamodb',\n",
    "                                   aws_access_key_id=os.environ[\"aws_access_key_id\"],\n",
    "                                   aws_secret_access_key=os.environ[\"aws_secret_access_key\"],\n",
    "                                   region_name=os.environ[\"region_name\"])\n",
    "        \n",
    "        parsed = []\n",
    "        for lookup_id in model_input[\"Id\"]:\n",
    "            raw_item = client.get_item(\n",
    "                TableName='HouseFeatures',\n",
    "                Key={'Id': {'S': lookup_id}})[\"Item\"]     \n",
    "            parsed_dict = {key: int(value['N']) if 'N' in value else value['S']\n",
    "                      for key, value in raw_item.items()}\n",
    "            parsed.append(parsed_dict)\n",
    "        lookup_df=pd.DataFrame(parsed)\n",
    "        merged_df = model_input.merge(lookup_df, on=\"Id\", how=\"left\").drop(\"Id\", axis=1)\n",
    "        \n",
    "        merged_df[\"GarageCars\"] = merged_df[\"GarageCars\"].fillna(2)\n",
    "        merged_df[\"GrLivArea\"] = merged_df[\"GrLivArea\"].fillna(1000)\n",
    "        merged_df[\"OverallQual\"] = merged_df[\"OverallQual\"].fillna(5)\n",
    "        merged_df[\"house_age\"] = datetime.now().year - merged_df[\"YearBuilt\"]\n",
    "        predictions = self.model.predict(merged_df)\n",
    "\n",
    "        return [int(x) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4cfee2d-e56b-42a2-9dd3-cd1d535900f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "custom_model = HousePriceModelWrapper(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73076178-5e04-4136-84d4-7d5936d32573",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "features = [f for f in [\"Id\"] + config.num_features + config.cat_features if f not in lookup_features]\n",
    "data = test_set.select(*features).toPandas()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21bece5e-09c1-496d-a81d-5d28f0a9bb12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "custom_model.predict(context=None, model_input=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf283543-c640-4f53-ae7c-1202577dd483",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#log model\n",
    "mlflow.set_experiment(\"/Shared/demo-model-fe-pyfunc\")\n",
    "with mlflow.start_run(run_name=\"demo-run-model-fe-pyfunc\",\n",
    "                      tags={\"git_sha\": \"1234567890abcd\",\n",
    "                            \"branch\": \"week2\"},\n",
    "                            description=\"demo run for FE model logging\") as run:\n",
    "    # Log parameters and metrics\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM with preprocessing\")\n",
    "    mlflow.log_params(config.parameters)\n",
    "\n",
    "    # Log the model\n",
    "    signature = infer_signature(model_input=data, model_output=custom_model.predict(context=None, model_input=data))\n",
    "    mlflow.pyfunc.log_model(\n",
    "                python_model=custom_model,\n",
    "                artifact_path=\"lightgbm-pipeline-model-fe\",\n",
    "                signature=signature,\n",
    "            )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c5f7717-0ec6-41fe-a00e-505eafd580a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "mlflow.models.predict(f\"runs:/{run_id}/lightgbm-pipeline-model-fe\", data[0:1])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "week3_feature_engineering",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}