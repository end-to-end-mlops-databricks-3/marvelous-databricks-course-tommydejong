{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a07fab2a-0a3e-440e-a64e-5896d54b99d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "726ed775-b6bc-4623-a8fb-4591e0f0037e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbd8d019-5140-4057-ac4e-85097461d9d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import mlflow\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from fifa_players.config import ProjectConfig\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from mlflow.models import infer_signature\n",
    "from marvelous.common import is_databricks\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from mlflow import MlflowClient\n",
    "import pandas as pd\n",
    "from fifa_players import __version__\n",
    "from mlflow.utils.environment import _mlflow_conda_env\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "if not is_databricks():\n",
    "    load_dotenv()\n",
    "    profile = os.environ[\"PROFILE\"]\n",
    "    mlflow.set_tracking_uri(f\"databricks://{profile}\")\n",
    "    mlflow.set_registry_uri(f\"databricks-uc://{profile}\")\n",
    "\n",
    "\n",
    "config = ProjectConfig.from_yaml(config_path=\"../project_config.yml\", env=\"dev\")\n",
    "\n",
    "# COMMAND ----------\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "train_set = spark.table(f\"{config.catalog_name}.{config.schema_name}.train_set\").toPandas()\n",
    "X_train = train_set[config.num_features + config.cat_features]\n",
    "y_train = train_set[config.target]\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[(\"preprocessor\", ColumnTransformer(\n",
    "            transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "                           config.cat_features)],\n",
    "            remainder=\"passthrough\")\n",
    "            ),\n",
    "               (\"regressor\", LGBMRegressor(**config.parameters))]\n",
    "        )\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# COMMAND ----------\n",
    "mlflow.set_experiment(\"/Shared/fifa-players-model\")\n",
    "with mlflow.start_run(run_name=\"fifa-players-model\",\n",
    "                      tags={\"git_sha\": \"1234567890abcd\",\n",
    "                            \"branch\": \"week2\"},\n",
    "                            description=\"fifa players run for model logging\") as run:\n",
    "    # Log parameters and metrics\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM with preprocessing\")\n",
    "    mlflow.log_params(config.parameters)\n",
    "\n",
    "    # Log the model\n",
    "    signature = infer_signature(model_input=X_train, model_output=pipeline.predict(X_train))\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=pipeline, artifact_path=\"lightgbm-pipeline-model\", signature=signature\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "# Load the model using the alias and test predictions - not recommended!\n",
    "# This may be working in a notebook but will fail on the endpoint\n",
    "artifact_uri = mlflow.get_run(run_id=run_id).to_dictionary()[\"info\"][\"artifact_uri\"]\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "model_name = f\"{config.catalog_name}.{config.schema_name}.model_demo\"\n",
    "model_version = mlflow.register_model(\n",
    "    model_uri=f'runs:/{run_id}/lightgbm-pipeline-model',\n",
    "    name=model_name,\n",
    "    tags={\"git_sha\": \"1234567890abcd\"})\n",
    "\n",
    "# COMMAND ----------\n",
    "# only searching by name is supported\n",
    "v = mlflow.search_model_versions(\n",
    "    filter_string=f\"name='{model_name}'\")\n",
    "print(v[0].__dict__)\n",
    "\n",
    "# COMMAND ----------\n",
    "client = MlflowClient()\n",
    "\n",
    "# COMMAND ----------\n",
    "# let's set latest-model alias instead\n",
    "\n",
    "client.set_registered_model_alias(\n",
    "    name=model_name,\n",
    "    alias=\"latest-model\",\n",
    "    version = model_version.version)\n",
    "\n",
    "# COMMAND ----------\n",
    "model_uri = f\"models:/{model_name}@latest-model\"\n",
    "sklearn_pipeline = mlflow.sklearn.load_model(model_uri)\n",
    "predictions = sklearn_pipeline.predict(X_train[0:1])\n",
    "print(predictions)\n",
    "\n",
    "# COMMAND ----------\n",
    "# A better way, also explained here\n",
    "#  will work in a later version of mlflow:\n",
    "# https://docs.databricks.com/aws/en/machine-learning/model-serving/model-serving-debug\n",
    "# https://www.databricksters.com/p/pyfunc-it-well-do-it-live\n",
    "\n",
    "# mlflow.models.predict(model_uri, X_train[0:1])\n",
    "\n",
    "# COMMAND ----------\n",
    "# Let's wrap it around a custom model\n",
    "from fifa_players.utils import adjust_predictions\n",
    "\n",
    "class FifaPlayersModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            predictions = self.model.predict(model_input)\n",
    "            predictions = {\"Prediction\": adjust_predictions(\n",
    "                predictions[0])}\n",
    "            return predictions\n",
    "        else:\n",
    "            raise ValueError(\"Input must be a pandas DataFrame.\")\n",
    "\n",
    "# COMMAND ----------\n",
    "wrapped_model = FifaPlayersModelWrapper(sklearn_pipeline) # we pass the loaded model to the wrapper\n",
    "\n",
    "mlflow.set_experiment(experiment_name=\"/Shared/fifa-players-pyfunc\")\n",
    "with mlflow.start_run(tags={\"branch\": \"feat/week2\",\n",
    "                            \"git_sha\": \"77889944ud\"}) as run:\n",
    "    run_id = run.info.run_id\n",
    "    signature = infer_signature(model_input=X_train, model_output={'Prediction': 1000.0})\n",
    "    conda_env = _mlflow_conda_env(\n",
    "        additional_conda_deps=None,\n",
    "        additional_pip_deps=[f\"code/fifa_players-{__version__}-py3-none-any.whl\",\n",
    "                             ],\n",
    "        additional_conda_channels=None,\n",
    "    )\n",
    "    mlflow.pyfunc.log_model(\n",
    "        python_model=wrapped_model,\n",
    "        artifact_path=\"pyfunc-house-price-model\",\n",
    "        code_paths = [f\"../dist/fifa_players-{__version__}-py3-none-any.whl\"],\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "# Another way of doing the same thing:\n",
    "\n",
    "from fifa_players.utils import adjust_predictions\n",
    "\n",
    "class FifaPlayersModelWrapper2(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def load_context(self, context):\n",
    "        self.model = mlflow.sklearn.load_model(\n",
    "            context.artifacts[\"lightgbm-pipeline-model\"]\n",
    "        )\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            predictions = self.model.predict(model_input)\n",
    "            predictions = {\"Prediction\": adjust_predictions(\n",
    "                predictions[0])}\n",
    "            return predictions\n",
    "        else:\n",
    "            raise ValueError(\"Input must be a pandas DataFrame.\")\n",
    "\n",
    "# COMMAND ----------\n",
    "mlflow.set_experiment(experiment_name=\"/Shared/fifa-players-pyfunc\")\n",
    "with mlflow.start_run(tags={\"branch\": \"feat/week2\",\n",
    "                            \"git_sha\": \"77889944ud\"}) as run:\n",
    "    run_id = run.info.run_id\n",
    "    signature = infer_signature(model_input=X_train, model_output={'Prediction': 1000.0})\n",
    "    conda_env = _mlflow_conda_env(\n",
    "        additional_conda_deps=None,\n",
    "        additional_pip_deps=[f\"code/fifa_players-{__version__}-py3-none-any.whl\",\n",
    "                             ],\n",
    "        additional_conda_channels=None,\n",
    "    )\n",
    "    mlflow.pyfunc.log_model(\n",
    "        python_model=FifaPlayersModelWrapper2(),\n",
    "        artifact_path=\"pyfunc-fifa-players-model\",\n",
    "        artifacts={\n",
    "            \"lightgbm-pipeline-model\": f\"models:/{model_name}@latest-model\"},\n",
    "        code_paths = [f\"../dist/fifa_players-{__version__}-py3-none-any.whl\"],\n",
    "        signature=signature\n",
    "    )\n",
    "# COMMAND ----------\n",
    "run_id\n",
    "# COMMAND ----------\n",
    "pyfunc_model = mlflow.pyfunc.load_model(f'runs:/{run_id}/pyfunc-fifa-players-model')\n",
    "# COMMAND ----------\n",
    "pyfunc_model.predict(X_train[0:1])\n",
    "# COMMAND ----------"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "week2_experiment_tracking",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
